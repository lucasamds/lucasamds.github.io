---
layout: post
title: Quantização vetorial com k-means
mathjax: true
---


<div class="message">
  Último post da série de processamento digital de imagens. Hoje vamos dar uma olhada na quantização vetorial utilizando o <em>k-means</em>.
</div>

Dizemos que uma quantização foi feita quando conseguimos mapear os dados de um conjunto grande em um conjunto de tamanho menor, como aqui em nossos experimentos trabalhamos com vetores, ao dividir os dados em grupos menores, ou seja, vetores menores, podemos dizer que foi feita uma quantização vetorial.

## k-means

Existem vários algoritmos que realizam a quantização vetorial, neste experimento vamos utilizar o método k-means. O algoritmo k-means vai separar os dados em células que são determinadas por um centro, de forma que, todos os pontos que possuírem uma distância para um determinado centro menor do que para os demais centros vão pertencer a mesma célula. O método funciona de acordo com a seguinte sequência.

1. Escolher um número de classes $$ k $$ para os vetores $$ x_{i} $$ de $$ N $$ amostras, com $$ i = 1, 2, ..., N $$.
2. Escolher as aproximações iniciais para os centros das classes $$ m_{1}, m_{2}, ..., m_{k} $$.
3. Classificar cada amostra com relação ao seu centro mais próximo, essa categorização vai ser feita com base em um classificador de distância mínima.
4. Com base no resultado do passo 3, recalcular as médias de cada grupo.
5. Se a variação entre as médias for muito baixa, considera-se que elas são consistentes e o algoritmo é encerrado. Caso a diferença de média ainda seja considerada relevante, é feito um novo cálculo para os centros e em seguida uma reclassificação dos dados.

Uma característica do algoritmo k-means é que ele vai gerar resultados diferentes para cada execução, devido a isso, é uma prática comum realizar algumas execuções do k-means e escolher a execução que gerou o melhor resultado. Neste experimento vamos aplicar o método em uma imagem colorida e comparar alguns resultados obtidos.


<a id="listagem1"></a>
##### Listagem 1. kmeans.py
{% highlight python %}

import numpy as np
import cv2 as cv
import sys

img = cv.imread('imagens/kmeans2.jpg')
if img is None:
    sys.exit('Imagem não encontrada')

height = img.shape[0]
width = img.shape[1]
nClusters = 16
nClusters_max = 50
nRodadas = 1
nRodadas_max = 10
samples = np.empty((height*width, 3), dtype=np.float32)
rotulos = np.empty(samples.shape, dtype=np.float32)


for y in range(height):
    for x in range(width):
        for z in range(3):
            samples[y+x*height, z] = img[y, x, z]

criteria = (cv.TERM_CRITERIA_MAX_ITER|cv.TERM_CRITERIA_EPS, 1000, 0.0001)


def fazkmeans():
    global rotulos
    rotulada = np.empty(img.shape, dtype=img.dtype)
    _,rotulos, centros = cv.kmeans(samples, nClusters, rotulos, criteria, nRodadas, cv.KMEANS_PP_CENTERS)
    for y in range(height):
        for x in range(width):
            indice = rotulos[y+x*height, 0]
            rotulada[y, x, 0] = np.uint8(centros[indice, 0])
            rotulada[y, x, 1] = np.uint8(centros[indice, 1])
            rotulada[y, x, 2] = np.uint8(centros[indice, 2])
    cv.imshow('Clustered image', rotulada)


def mudouncluster(x):
    global nClusters
    nClusters = x
    fazkmeans()


def mudounrodadas(x):
    global nRodadas
    nRodadas = x
    fazkmeans()

cv.namedWindow('Clustered image', cv.WINDOW_AUTOSIZE)
cv.createTrackbar('nClusters', 'Clustered image', nClusters, nClusters_max, mudouncluster)
cv.createTrackbar('nRodadas', 'Clustered image', nRodadas, nRodadas_max, mudounrodadas)
fazkmeans()
cv.waitKey()

{% endhighlight %}

## Descrição do programa kmeans.py

{% highlight python %}
samples = np.empty((height*width, 3), dtype=np.float32)
rotulos = np.empty(samples.shape, dtype=np.float32)
{% endhighlight %}


Primeiramente criamos uma matriz de amostras `samples`, neste caso vamos pegar todos os valores da imagem, como iremos trabalhar com uma imagem colorida, teremos 3 colunas, onde cada coluna irá armazenar uma das componentes **RGB**. Já  matriz  `rotulos` vai rotular cada elemento de `samples`.

{% highlight python %}
criteria = (cv.TERM_CRITERIA_MAX_ITER|cv.TERM_CRITERIA_EPS, 1000, 0.0001)
{% endhighlight %}

Um outro parâmetro que vamos precisar criar, antes de aplicar o k-means, é o critério de parada que o algoritmo deve seguir. Este critério é representado por uma tupla de 3 parâmetros, sendo elas: O tipo do critério de parada, no nosso caso estamos dizendo que o processo encerra ao se alcançar o número máximo de iterações ou caso a acurácia requerida seja alcançada; um inteiro representando o número máximo de iterações; um valor real que indica a acurácia desejada.

{% highlight python %}
def fazkmeans():
    global rotulos
    rotulada = np.empty(img.shape, dtype=img.dtype)
    _,rotulos, centros = cv.kmeans(samples, nClusters, rotulos, criteria, nRodadas, cv.KMEANS_PP_CENTERS)
    for y in range(height):
        for x in range(width):
            indice = rotulos[y+x*height, 0]
            rotulada[y, x, 0] = np.uint8(centros[indice, 0])
            rotulada[y, x, 1] = np.uint8(centros[indice, 1])
            rotulada[y, x, 2] = np.uint8(centros[indice, 2])
    cv.imshow('Clustered image', rotulada)

{% endhighlight %}

A principal função do nosso programa é a `fazkmeans()`, nela vamos realizar a aplicação do k-means e apresentar os resultados obtidos em tela. A matriz `rotulada` irá receber o resultado da imagem após ter passado pelo k-means. A função `kmeans()` do OpenCV recebe os seguintes parâmetros: Amostras que serão classificadas; o número de classes que iremos utilizar; a matriz que irá receber a rotulagem das amostras; o critério de parada do algoritmo; a quantidade de vezes que o k-means será aplicado, retornando a melhor execução dentre elas; uma *flag* que especifica como os centros iniciais são gerados, aqui vamos utilizar a *flag* de centros randômicos. Ao concluir a função `kmeans()`, teremos na matriz `rotulos` o grupo que cada elemento da imagem pertence, em `centros` estarão armazenados os valores de cada centro final, encontrados na aplicação do k-means.

A última tarefa é gerar a nova imagem, utilizando os agrupamentos encontrados. Temos que, para cada elemento da imagem de saída, verifica-se a qual classe ele pertence e em seguida pegamos o valor do centro daquela classe, no nosso caso será a cor a qual os elementos daquela classe irão apresentar; este processo é realizado para as três camadas de cores do modelo **RGB**.

Vejamos abaixo o que acontece quando variamos a quantidade de grupos que o k-means pode apresentar.

<iframe src="https://www.youtube.com/embed/1DeZYJ894W4?vq=hd1080&showinfo=0&rel=0&iv_load_policy=3" width="560" height="315" frameborder="0"></iframe>
<em class="descricao">Vídeo 1. Variando a quantidade de classes no k-means</em>

Como podemos perceber, a medida que o número de agrupamentos possíveis aumenta, mais próximo ao conteúdo original nós chegamos.

Agora vamos ver o que acontece quando variamos a quantidade de vezes que o k-means é aplicado.

<iframe src="https://www.youtube.com/embed/zWkJWeEcaic?vq=hd1080&showinfo=0&rel=0&iv_load_policy=3" width="560" height="315" frameborder="0"></iframe>
<em class="descricao">Vídeo 2. Diferentes resultados do k-means</em>

Como falamos anteriormente, diferetentes execuções do algoritmo k-means vão gerar resultados diferentes, como escolhemos para os centros inicias serem gerados de forma aleatória, este efeito fica ainda mais evidente, já que um centro pode estar, inicialmente, muito distante de seu posicionamento final.

Com este exemplo de quantização vetorial, encerro por hora esta série sobre processamento digital de imagem, se você acompanhou um ou mais posts da série, fico extemamente agradecido pela atenção e espero que tenha aprendido algo novo, nos vemos em uma próxima!